{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlphaFold2_batch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dthorburn/rb_automation/blob/main/af2_small_batch/AlphaFold2_batch_RBGCP_current.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "#ColabFold v1.5.5: AlphaFold2 w/ MMseqs2 BATCH & GCP Bucket Access\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"256\" align=\"right\" style=\"height:256px\">\n",
        "\n",
        "# Instructions <a name=\"Instructions\"></a>\n",
        "**Quick start**\n",
        "1. Upload your AA sequences in fasta format to GCP (NB. files must be appended with `.fasta` to be identified as fasta here.\n",
        "2. Define GCP project ID using (`project_name`), then path to the GCP cloud storage bucket and sub-directory containing the fasta files using (`bucket_name`) define an outdir (`folder_name`).\n",
        "3. Check the parameters are correctly set. Defaults are fine for most use cases.\n",
        "4. Launch GCP GPU VM with Colab backend container using this [link]( https://console.cloud.google.com/marketplace/product/colab-marketplace-image-public/colab) (ensure you are logged into our GCP account). An NVIDIA T4 with 4 vCPU and 13Gb-26Gb of memory should be sufficient for most use cases.\n",
        "5. Select `Connect to a custom GCE VM` under connection options in the top right and follow instructions.\n",
        "6. Once connected, press `Runtime` -> `Run all` (Or select each block and run individually).\n",
        "7. Follow the link provided to retrieve temporary access code to GCP during execution of the first block and paste it in the proivded space.\n",
        "\n",
        "**Output**\n",
        "1. A new directory will be made in the same folder as the `folder_name` variable below called `Completed_${folder_name}`.\n",
        "2. For each prediction, 1 PDB files and 2 JSON files will be uploaded to the output directory.\n",
        "3. This output directory can be used as input for the RB candidate genes protein-protein interaction scoring pipeline.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwvIWN3HDyUJ",
        "cellView": "form"
      },
      "source": [
        "#@title Access GCP files\n",
        "!pip install --upgrade google-cloud-storage\n",
        "!gcloud auth application-default login\n",
        "\n",
        "from google.cloud import storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fetch inputs from Google Cloud Storage\n",
        "\n",
        "#@markdown ## Set parameters to get input files run and wait for summary. Check correct before running Alphafold\n",
        "#@markdown ## Note: Will remove input directory and contents if you run this cell.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "project_name = '' #@param {type:\"string\"}\n",
        "bucket_name = '' #@param {type:\"string\"}\n",
        "folder_name = '' #@param {type:\"string\"}\n",
        "\n",
        "print(\"Ensuring download folder free\")\n",
        "input_local_dir = Path.home().resolve() / \"input\"\n",
        "\n",
        "if os.path.isdir(input_local_dir):\n",
        "  print(\"Removing existing data from input dir\")\n",
        "  shutil.rmtree(input_local_dir)\n",
        "\n",
        "os.mkdir(input_local_dir)\n",
        "\n",
        "\n",
        "print(\"Fetching data...\")\n",
        "storage_client = storage.Client(project_name)\n",
        "bucket = storage_client.get_bucket(bucket_name)\n",
        "blobs = bucket.list_blobs(prefix=folder_name)  # Get list of files\n",
        "for blob in blobs:\n",
        "  filename = blob.name.split(\"/\")[-1]\n",
        "  if bool(re.search(\"fasta\", str(filename))):\n",
        "    blob.download_to_filename(input_local_dir.resolve() / filename)\n",
        "#for blob in blobs:\n",
        "#  blob.download_to_filename(input_local_dir.resolve() / blob.name.split(\"/\")[-1])\n",
        "\n",
        "print(\"Done, input directory state:\")\n",
        "print(os.listdir(input_local_dir))"
      ],
      "metadata": {
        "id": "1ZlteYLrGH_9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOblAo-xetgx",
        "cellView": "form"
      },
      "source": [
        "#@title Settings\n",
        "#input_dir = '/content/drive/MyDrive/input_fasta' #@param {type:\"string\"}\n",
        "#result_dir = '/content/drive/MyDrive/result' #@param {type:\"string\"}\n",
        "\n",
        "## Adding a temp directory for input files that have been run\n",
        "input_dir = input_local_dir\n",
        "result_dir = Path.home().resolve() / \"output\"\n",
        "finished_dir = Path.home().resolve() / \"finished\"\n",
        "uploaded_dir = Path.home().resolve() / \"uploaded\"\n",
        "working_dir = Path.home().resolve() / \"temp_work\"\n",
        "\n",
        "#os.mkdir(result_dir)\n",
        "#os.mkdir(finished_dir)\n",
        "#os.mkdir(working_dir)\n",
        "#os.mkdir(uploaded_dir)\n",
        "\n",
        "# number of models to use\n",
        "\n",
        "#@markdown ### Advanced settings\n",
        "msa_mode = \"MMseqs2 (UniRef+Environmental)\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
        "num_models = 1 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "num_recycles = 3 #@param {type:\"raw\"}\n",
        "stop_at_score = 100 #@param {type:\"string\"}\n",
        "use_custom_msa = False\n",
        "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "use_amber = num_relax > 0\n",
        "relax_max_iterations = 200 #@param [0,200,2000] {type:\"raw\"}\n",
        "use_templates = False #@param {type:\"boolean\"}\n",
        "do_not_overwrite_results = True #@param {type:\"boolean\"}\n",
        "zip_results = False #@param {type:\"boolean\"}\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccGdbe_Pmt9",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_templates $python_version\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "PYTHON_VERSION=$3\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# Download params (~1min)\n",
        "python -m colabfold.download\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniconda3-latest-Linux-x86_64.sh\n",
        "    conda config --set auto_update_conda false\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  conda install -y -q -c conda-forge openmm=7.7.0 python=\"${PYTHON_VERSION}\" pdbfixer 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYApPElB30u",
        "cellView": "form"
      },
      "source": [
        "#@title Run Prediction\n",
        "\n",
        "import sys\n",
        "\n",
        "from colabfold.batch import get_queries, run\n",
        "from colabfold.download import default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from pathlib import Path\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "setup_logging(Path(result_dir).joinpath(\"log.txt\"))\n",
        "\n",
        "# make the folder to upload is visible\n",
        "storage_client = storage.Client(project_name)\n",
        "bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    print(\"Starting: \" + filename)\n",
        "    if os.path.isfile(input_dir.resolve()/ filename):\n",
        "        shutil.move(input_dir.resolve()/ filename, working_dir.resolve())\n",
        "\n",
        "    queries, is_complex = get_queries(working_dir)\n",
        "    run(\n",
        "      queries=queries,\n",
        "      result_dir=result_dir,\n",
        "      use_templates=use_templates,\n",
        "      num_relax=num_relax,\n",
        "      relax_max_iterations=relax_max_iterations,\n",
        "      msa_mode=msa_mode,\n",
        "      model_type=\"auto\",\n",
        "      num_models=num_models,\n",
        "      num_recycles=num_recycles,\n",
        "      model_order=[1, 2, 3, 4, 5],\n",
        "      is_complex=is_complex,\n",
        "      data_dir=default_data_dir,\n",
        "      keep_existing_results=do_not_overwrite_results,\n",
        "      rank_by=\"auto\",\n",
        "      pair_mode=\"unpaired+paired\",\n",
        "      stop_at_score=stop_at_score,\n",
        "      zip_results=zip_results,\n",
        "      user_agent=\"colabfold/google-colab-batch\",\n",
        "    )\n",
        "    print('Moving input file...')\n",
        "    shutil.move(working_dir.resolve()/ filename, finished_dir.resolve())\n",
        "\n",
        "    print('Uploading results...')\n",
        "    for filename in os.listdir(result_dir):\n",
        "      if os.path.isfile(result_dir.resolve()/ filename):\n",
        "          blob = bucket.blob(\"Completed_\" + folder_name + \"/\" + filename)\n",
        "          blob.upload_from_filename(result_dir.resolve()/ filename)\n",
        "          shutil.move(os.path.join(result_dir, filename), os.path.join(uploaded_dir, filename))\n",
        "    print('Done. Moving on to next sample...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN"
      },
      "source": [
        "**Limitations**\n",
        "\n",
        "MSAs: MMseqs2 is very precise and sensitive but might find less hits compared to HHblits/HMMer searched against BFD or Mgnify.\n",
        "\n",
        "**License**\n",
        "\n",
        "The source code of ColabFold is licensed under [MIT](https://raw.githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Additionally, this notebook uses AlphaFold2 source code and its parameters licensed under [Apache 2.0](https://raw.githubusercontent.com/deepmind/alphafold/main/LICENSE) and  [CC BY 4.0](https://creativecommons.org/licenses/by-sa/4.0/) respectively. Read more about the AlphaFold license [here](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Acknowledgments**\n",
        "- We thank the AlphaFold team for developing an excellent model and open sourcing the software.\n",
        "- Do-Yoon Kim for creating the ColabFold logo.\n",
        "- A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n"
      ]
    }
  ]
}